{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "horizontal-howard",
   "metadata": {},
   "source": [
    "# Dask vs Pandas speed tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-fault",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Dask based on Tornado and first release was in 2015 (before asyncio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-member",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import dask.dataframe as dd\n",
    "# from dask.diagnostics import ProgressBar  # single machine progressbar\n",
    "# from dask.distributed import progress  # does it work?\n",
    "from dask.distributed import Client  # has dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-leone",
   "metadata": {},
   "source": [
    "Articles:\n",
    "+ CSV to Parquet with Dask: <https://mungingdata.com/dask/read-csv-to-parquet/>\n",
    "+ https://towardsdatascience.com/beyond-pandas-spark-dask-vaex-and-other-big-data-technologies-battling-head-to-head-a453a1f8cc13\n",
    "+ https://towardsdatascience.com/make-your-data-processing-code-fly-in-5-minutes-c4998e6da094\n",
    "+ https://stackoverflow.com/questions/47191675/pandas-write-dataframe-to-parquet-format-with-append\n",
    "\n",
    "Issues:\n",
    "+ https://stackoverflow.com/questions/60173358/distributed-worker-memory-use-is-high-but-worker-has-no-data-to-store-to-disk\n",
    "+ https://github.com/dask/distributed/issues/4594\n",
    "\n",
    "Results:\n",
    "+ no reindex for dask\n",
    "+ No \"Try using .loc[row_indexer,col_indexer] = value instead\" warning in dask\n",
    "+ No append for parquet for both (possible with pandas and pyarrow)\n",
    "+ CSV:\n",
    "    + no gzip input for CSV in dask\n",
    "    + 35 min (dask csv -> csv) vs 55 min (pandas gz -> gz) vs 55 min (pd csv -> csv)\n",
    "    + 550 output csv files (56GB) vs 1 (5GB)\n",
    "+ parquet:\n",
    "    + dask + pyarrow is not working, but takes 11 min\n",
    "    + dask + fastparquet 14 min, 554 files (58GB) (compression unknown) vs 33 files\n",
    "    + pandas ~27 min (csv -> fastparquet) (snappy, ~7GB)\n",
    "    + pandas ~37 min (csv -> fastparquet) (gzip, ~3.7GB)\n",
    "    + pandas ~25 min (csv -> fastparquet) (uncompressed, 45GB)\n",
    "    + **pandas ~20 min (csv -> pyarrow) (snappy, ~5GB)**\n",
    "    + pandas ~28 min (csv -> pyarrow) (gzip, ~3.7GB)\n",
    "    + pandas ~33 min (csv -> pyarrow) (brotli, ~3GB)\n",
    "    + **pandas 20 min (*gz* -> pyarrow) (snappy, 5GB)** vs 33 files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "anonymous-mustang",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/mimic-iii-clinical-database-1.4/'\n",
    "output_path = './data/fhir_out/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-grammar",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-palace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import gc\n",
    "\n",
    "\n",
    "def transform_chartevents(data_path, output_path, chunksize=10**7):\n",
    "    \"\"\" ~6GB RAM in peak consumption with default chunksize\n",
    "    \"\"\"\n",
    "    # delete outputfile if exists\n",
    "    output_filename = output_path+'observation_ce'\n",
    "    Path(output_filename).unlink(missing_ok=True)\n",
    "    \n",
    "    d_items = pd.read_csv(data_path+'D_ITEMS.csv.gz', index_col=0,\n",
    "                      # dropped 'ABBREVIATION', 'LINKSTO', 'CONCEPTID', 'UNITNAME'\n",
    "                      usecols=['ROW_ID', 'ITEMID', 'LABEL', 'DBSOURCE', 'CATEGORY', 'PARAM_TYPE'],\n",
    "                      dtype={'ROW_ID': int, 'ITEMID': int, 'LABEL': str, 'DBSOURCE': 'category',\n",
    "                             'CATEGORY': 'category', 'PARAM_TYPE': str})\n",
    "    \n",
    "    # it is the biggest file ~4GB gzipped, 33GB unpacked, 330M strings\n",
    "    # looks like CareVue and Metavision data should be processed separately\n",
    "    chunk_container =  pd.read_csv(data_path+'CHARTEVENTS.csv.gz',\n",
    "                                   # STORETIME\n",
    "                                   usecols=['ROW_ID', 'SUBJECT_ID', 'HADM_ID', 'ICUSTAY_ID', 'ITEMID', 'CHARTTIME',\n",
    "                                            'STORETIME', 'CGID', 'VALUE', 'VALUENUM', 'VALUEUOM', 'WARNING', 'ERROR',\n",
    "                                            'RESULTSTATUS', 'STOPPED'],\n",
    "                                   dtype={'ROW_ID': int, 'SUBJECT_ID': int, 'HADM_ID': int, 'ICUSTAY_ID': float,\n",
    "                                          'ITEMID': int, 'CGID': float, 'VALUE': str, 'VALUENUM': float, \n",
    "                                          'VALUEUOM': str, 'WARNING': float, 'ERROR': float,\n",
    "                                          'RESULTSTATUS': str, 'STOPPED': str},\n",
    "                                   parse_dates=['CHARTTIME'],\n",
    "                                   chunksize=chunksize)  # 2.67GB for 10**7\n",
    "    \n",
    "    for i, chartevents in enumerate(chunk_container):\n",
    "        # Show progress (~330M strings)\n",
    "        print(f'{i + 1}/{330*10**6 / chunksize}', flush=True, end =\" \")\n",
    "        start_time = time.time()\n",
    "\n",
    "        observation_ce = pd.merge(chartevents, d_items, on='ITEMID')\n",
    "\n",
    "        observation_ce['note'] = observation_ce['LABEL'].str.cat(observation_ce['DBSOURCE'], sep=' ', na_rep='NA')\n",
    "        observation_ce['note'] = observation_ce['note'].str.cat(observation_ce['PARAM_TYPE'], sep=' ', na_rep='')\n",
    "\n",
    "        observation_ce.loc[observation_ce['STOPPED'] == \"D/C'd\", 'RESULTSTATUS'] = 'discharged'\n",
    "        observation_ce.loc[observation_ce['ERROR'] == 1, 'RESULTSTATUS'] = 'Error'\n",
    "        \n",
    "        # New columns to adapt to Chartevents observations\n",
    "        observation_ce['category'] = 'chartevents'  # ????\n",
    "\n",
    "        observation_ce.drop(['LABEL', 'PARAM_TYPE', 'ERROR', 'DBSOURCE', 'STOPPED'], axis=1, inplace=True)\n",
    "\n",
    "        observation_ce.rename(columns={'ROW_ID':'identifier',\n",
    "                                       'SUBJECT_ID':'subject',\n",
    "                                       'HADM_ID':'encounter',                               \n",
    "                                       'ICUSTAY_ID':'partOf',\n",
    "                                       'ITEMID':'code',\n",
    "                                       'CGID':'performer',\n",
    "                                       'CHARTTIME':'effectiveDateTime',\n",
    "                                       'VALUE':'value',\n",
    "                                       'VALUENUM':'value_quantity',\n",
    "                                       'VALUEUOM':'unit',\n",
    "                                       'WARNING':'interpretation',\n",
    "                                       'RESULTSTATUS':'status',\n",
    "                                       'CATEGORY':'category_sub'}, inplace=True)\n",
    "\n",
    "        observation_ce = observation_ce.reindex(columns=['identifier',\n",
    "                                                         'subject', \n",
    "                                                         'encounter', \n",
    "                                                         'partOf', \n",
    "                                                         'code',\n",
    "                                                         'effectiveDateTime',\n",
    "                                                         'performer',\n",
    "                                                         'value',\n",
    "                                                         'value_quantity',\n",
    "                                                         'unit', \n",
    "                                                         'interpretation',\n",
    "                                                         'status',\n",
    "                                                         'note',\n",
    "                                                         'category_sub',\n",
    "                                                         'category'], copy=False)\n",
    "\n",
    "#         observation_ce.to_csv(output_filename + '.csv.gz',\n",
    "#                               compression={'method': 'gzip', 'compresslevel': 1},\n",
    "#                               index=False, mode='a')\n",
    "        \n",
    "#         observation_ce.to_csv(output_filename + '.csv', index=False, mode='a')\n",
    "        \n",
    "        # will create a lot of files, no append mode\n",
    "        observation_ce.to_parquet(f\"{output_filename}_{i}.parquet\", \n",
    "                                  compression='snappy', index=False)\n",
    "\n",
    "        # force free mem, for some reasons without it, RAM ends pretty quick\n",
    "        gc.collect()\n",
    "        # show execution time per chunk\n",
    "        print(f\"--- {time.time() - start_time} seconds ---\", flush=True)\n",
    "\n",
    "        \n",
    "transform_chartevents(data_path, output_path)\n",
    "# observation_ce = transform_chartevents(data_path, output_path)\n",
    "# observation_ce.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-small",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "annual-enlargement",
   "metadata": {},
   "source": [
    "## Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_items = pd.read_csv(data_path+'D_ITEMS.csv.gz', index_col=0,\n",
    "                  # dropped 'ABBREVIATION', 'LINKSTO', 'CONCEPTID', 'UNITNAME'\n",
    "                  usecols=['ROW_ID', 'ITEMID', 'LABEL', 'DBSOURCE', 'CATEGORY', 'PARAM_TYPE'],\n",
    "                  dtype={'ROW_ID': int, 'ITEMID': int, 'LABEL': str, 'DBSOURCE': 'category',\n",
    "                         'CATEGORY': 'category', 'PARAM_TYPE': str})\n",
    "\n",
    "d_items.set_index('ITEMID', inplace=True)\n",
    "d_items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = Client(threads_per_worker=2, n_workers=4, memory_limit='2.5GB')\n",
    "client = Client()  # it will consume all memory by default\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning gzip compression does not support breaking apart files\n",
    "# Q: what default blocksize? A: https://github.com/dask/dask/pull/1328 (32M)\n",
    "# max 64e6 bytes ~61MB\n",
    "df =  dd.read_csv(data_path + 'CHARTEVENTS' + '.csv',\n",
    "                  usecols=['ROW_ID', 'SUBJECT_ID', 'HADM_ID', 'ICUSTAY_ID', 'ITEMID', 'CHARTTIME',\n",
    "                           'STORETIME', 'CGID', 'VALUE', 'VALUENUM', 'VALUEUOM', 'WARNING', 'ERROR',\n",
    "                           'RESULTSTATUS', 'STOPPED'],\n",
    "                  dtype={'ROW_ID': int, 'SUBJECT_ID': int, 'HADM_ID': int, 'ICUSTAY_ID': float,\n",
    "                         'ITEMID': int, 'CGID': float, 'VALUE': str, 'VALUENUM': float, \n",
    "                         'VALUEUOM': str, 'WARNING': float, 'ERROR': float,\n",
    "                         'RESULTSTATUS': str, 'STOPPED': str},\n",
    "                  parse_dates=['CHARTTIME'])\n",
    "#                   blocksize=96*1024*1024)  # 64MB max?\n",
    "\n",
    "# it will take a while, like 4min\n",
    "# raises \"TypeError: memoryview: cannot cast view with zeros in shape or strides\"\n",
    "# at the final stages\n",
    "# df = df.set_index('ITEMID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-tumor",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_ce = dd.merge(df, d_items, left_on='ITEMID', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = output_path+'observation_ce'\n",
    "\n",
    "observation_ce['note'] = observation_ce['LABEL'].str.cat(observation_ce['DBSOURCE'], sep=' ', na_rep='NA')\n",
    "observation_ce['note'] = observation_ce['note'].str.cat(observation_ce['PARAM_TYPE'], sep=' ', na_rep='')\n",
    "\n",
    "# No \"Try using .loc[row_indexer,col_indexer] = value instead\" warning\n",
    "# .loc way is not implemented/usable in dask\n",
    "mask = observation_ce['STOPPED'] == \"D/C'd\"\n",
    "observation_ce[mask]['RESULTSTATUS'] = 'discharged'\n",
    "mask2 = observation_ce['ERROR'] == 1\n",
    "observation_ce[mask]['RESULTSTATUS'] = 'Error'\n",
    "\n",
    "# New columns to adapt to Chartevents observations\n",
    "observation_ce['category'] = 'chartevents'  # ????\n",
    "\n",
    "observation_ce.drop(columns=['LABEL', 'PARAM_TYPE', 'ERROR', 'DBSOURCE', 'STOPPED'])\n",
    "\n",
    "observation_ce.rename(columns={'ROW_ID':'identifier',\n",
    "                               'SUBJECT_ID':'subject',\n",
    "                               'HADM_ID':'encounter',                               \n",
    "                               'ICUSTAY_ID':'partOf',\n",
    "                               'ITEMID':'code',\n",
    "                               'CGID':'performer',\n",
    "                               'CHARTTIME':'effectiveDateTime',\n",
    "                               'VALUE':'value',\n",
    "                               'VALUENUM':'value_quantity',\n",
    "                               'VALUEUOM':'unit',\n",
    "                               'WARNING':'interpretation',\n",
    "                               'RESULTSTATUS':'status',\n",
    "                               'CATEGORY':'category_sub'})\n",
    "\n",
    "# dask loves parquet\n",
    "# using pyarrow: https://github.com/dask/dask/issues/6587\n",
    "# observation_ce.to_csv(output_filename + '.csv')\n",
    "observation_ce.to_parquet(output_filename + '.parquet', schema=\"infer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-sewing",
   "metadata": {},
   "source": [
    "Attemt to use `map_partition(foo)` failed with issues from header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-incidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/41806850/dask-difference-between-client-persist-and-client-compute\n",
    "# observation_ce.persist()  # in bg\n",
    "# observation_ce.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-soccer",
   "metadata": {},
   "source": [
    "## parquet to single file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-detector",
   "metadata": {},
   "source": [
    "+ https://arrow.apache.org/docs/python/dataset.html\n",
    "+ https://stackoverflow.com/questions/47191675/pandas-write-dataframe-to-parquet-format-with-append\n",
    "+ **https://stackoverflow.com/questions/47113813/using-pyarrow-how-do-you-append-to-parquet-file**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-terminal",
   "metadata": {},
   "source": [
    "### use dataset\n",
    "\n",
    "it need to be dowloaded into the memory in order to save as a single file\n",
    "\n",
    "https://arrow.apache.org/docs/python/generated/pyarrow.dataset.Dataset.html#pyarrow.dataset.Dataset.to_table\n",
    ">Note that this method reads all the selected data from the dataset into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "junior-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "\n",
    "data_path = './data/mimic-iii-clinical-database-1.4/'\n",
    "output = \"mydataset.parquet\"\n",
    "\n",
    "d_items = pd.read_csv(data_path+'D_ITEMS.csv.gz', index_col=0,\n",
    "                  # dropped 'ABBREVIATION', 'LINKSTO', 'CONCEPTID', 'UNITNAME'\n",
    "                  usecols=['ROW_ID', 'ITEMID', 'LABEL', 'DBSOURCE', 'CATEGORY', 'PARAM_TYPE'],\n",
    "                  dtype={'ROW_ID': int, 'ITEMID': int, 'LABEL': str, 'DBSOURCE': str,\n",
    "                         'CATEGORY': str, 'PARAM_TYPE': str}, chunksize=1000)\n",
    "\n",
    "for i, chunk in enumerate(d_items):\n",
    "    # create a parquet table from your dataframe\n",
    "    table = pa.Table.from_pandas(chunk)\n",
    "    if i == 0:\n",
    "        schema = table.schema\n",
    "    # write direct to your parquet file\n",
    "    pq.write_to_dataset(table, root_path=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "taken-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tru to convert dataset to a single file\n",
    "# dataset = ds.dataset(output, schema=schema)\n",
    "dataset = ds.dataset(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "peripheral-margin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.Table\n",
       "ITEMID: int64\n",
       "LABEL: string\n",
       "DBSOURCE: string\n",
       "CATEGORY: string\n",
       "PARAM_TYPE: string\n",
       "ROW_ID: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it will load all into the memory\n",
    "dataset.to_table()\n",
    "# pq.read_table(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "accurate-narrative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITEMID: int64\n",
      "  -- field metadata --\n",
      "  PARQUET:field_id: '1'\n",
      "LABEL: string\n",
      "  -- field metadata --\n",
      "  PARQUET:field_id: '2'\n",
      "DBSOURCE: string\n",
      "  -- field metadata --\n",
      "  PARQUET:field_id: '3'\n",
      "CATEGORY: string\n",
      "  -- field metadata --\n",
      "  PARQUET:field_id: '4'\n",
      "PARAM_TYPE: string\n",
      "  -- field metadata --\n",
      "  PARQUET:field_id: '5'\n",
      "ROW_ID: int64\n",
      "  -- field metadata --\n",
      "  PARQUET:field_id: '6'\n",
      "-- schema metadata --\n",
      "pandas: '{\"index_columns\": [\"ROW_ID\"], \"column_indexes\": [{\"name\": null, ' + 881\n"
     ]
    }
   ],
   "source": [
    " print(dataset.schema.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "prompt-status",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITEMID: int64\n",
      "LABEL: string\n",
      "DBSOURCE: string\n",
      "CATEGORY: string\n",
      "PARAM_TYPE: null\n",
      "ROW_ID: int64\n",
      "-- schema metadata --\n",
      "pandas: '{\"index_columns\": [\"ROW_ID\"], \"column_indexes\": [{\"name\": null, ' + 879\n"
     ]
    }
   ],
   "source": [
    " print(schema.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-french",
   "metadata": {},
   "source": [
    "### use single file from start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "designed-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize=10000 # this is the number of lines\n",
    "\n",
    "pqwriter = None\n",
    "for i, df in enumerate(pd.read_csv(data_path+'D_ITEMS.csv.gz', index_col=0,\n",
    "                  # dropped 'ABBREVIATION', 'LINKSTO', 'CONCEPTID', 'UNITNAME'\n",
    "                  usecols=['ROW_ID', 'ITEMID', 'LABEL', 'DBSOURCE', 'CATEGORY', 'PARAM_TYPE'],\n",
    "                  dtype={'ROW_ID': int, 'ITEMID': int, 'LABEL': str, 'DBSOURCE': str,\n",
    "                         'CATEGORY': str, 'PARAM_TYPE': str}, chunksize=chunksize)):\n",
    "    table = pa.Table.from_pandas(df)\n",
    "    # for the first chunk of records\n",
    "    if i == 0:\n",
    "        # create a parquet write object giving it an output file\n",
    "        pqwriter = pq.ParquetWriter('sample.parquet', table.schema)            \n",
    "    pqwriter.write_table(table)\n",
    "\n",
    "# close the parquet writer\n",
    "if pqwriter:\n",
    "    pqwriter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "essential-plaintiff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITEMID</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>DBSOURCE</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>PARAM_TYPE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROW_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>497</td>\n",
       "      <td>Patient controlled analgesia (PCA) [Inject]</td>\n",
       "      <td>carevue</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>498</td>\n",
       "      <td>PCA Lockout (Min)</td>\n",
       "      <td>carevue</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>499</td>\n",
       "      <td>PCA Medication</td>\n",
       "      <td>carevue</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>500</td>\n",
       "      <td>PCA Total Dose</td>\n",
       "      <td>carevue</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>501</td>\n",
       "      <td>PCV Exh Vt (Obser)</td>\n",
       "      <td>carevue</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14518</th>\n",
       "      <td>226757</td>\n",
       "      <td>GCSMotorApacheIIValue</td>\n",
       "      <td>metavision</td>\n",
       "      <td>Scores - APACHE II</td>\n",
       "      <td>Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14519</th>\n",
       "      <td>226758</td>\n",
       "      <td>GCSVerbalApacheIIValue</td>\n",
       "      <td>metavision</td>\n",
       "      <td>Scores - APACHE II</td>\n",
       "      <td>Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14520</th>\n",
       "      <td>226759</td>\n",
       "      <td>HCO3ApacheIIValue</td>\n",
       "      <td>metavision</td>\n",
       "      <td>Scores - APACHE II</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14521</th>\n",
       "      <td>226760</td>\n",
       "      <td>HCO3Score</td>\n",
       "      <td>metavision</td>\n",
       "      <td>Scores - APACHE II</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14522</th>\n",
       "      <td>226761</td>\n",
       "      <td>HematocritApacheIIScore</td>\n",
       "      <td>metavision</td>\n",
       "      <td>Scores - APACHE II</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12487 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ITEMID                                        LABEL    DBSOURCE  \\\n",
       "ROW_ID                                                                    \n",
       "457        497  Patient controlled analgesia (PCA) [Inject]     carevue   \n",
       "458        498                            PCA Lockout (Min)     carevue   \n",
       "459        499                               PCA Medication     carevue   \n",
       "460        500                               PCA Total Dose     carevue   \n",
       "461        501                           PCV Exh Vt (Obser)     carevue   \n",
       "...        ...                                          ...         ...   \n",
       "14518   226757                        GCSMotorApacheIIValue  metavision   \n",
       "14519   226758                       GCSVerbalApacheIIValue  metavision   \n",
       "14520   226759                            HCO3ApacheIIValue  metavision   \n",
       "14521   226760                                    HCO3Score  metavision   \n",
       "14522   226761                      HematocritApacheIIScore  metavision   \n",
       "\n",
       "                  CATEGORY PARAM_TYPE  \n",
       "ROW_ID                                 \n",
       "457                   None       None  \n",
       "458                   None       None  \n",
       "459                   None       None  \n",
       "460                   None       None  \n",
       "461                   None       None  \n",
       "...                    ...        ...  \n",
       "14518   Scores - APACHE II       Text  \n",
       "14519   Scores - APACHE II       Text  \n",
       "14520   Scores - APACHE II    Numeric  \n",
       "14521   Scores - APACHE II    Numeric  \n",
       "14522   Scores - APACHE II    Numeric  \n",
       "\n",
       "[12487 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet('sample.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "further-lodge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITEMID</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>DBSOURCE</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>PARAM_TYPE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROW_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>497</td>\n",
       "      <td>Patient controlled analgesia (PCA) [Inject]</td>\n",
       "      <td>carevue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>498</td>\n",
       "      <td>PCA Lockout (Min)</td>\n",
       "      <td>carevue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>499</td>\n",
       "      <td>PCA Medication</td>\n",
       "      <td>carevue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>500</td>\n",
       "      <td>PCA Total Dose</td>\n",
       "      <td>carevue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>501</td>\n",
       "      <td>PCV Exh Vt (Obser)</td>\n",
       "      <td>carevue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14518</th>\n",
       "      <td>226757</td>\n",
       "      <td>GCSMotorApacheIIValue</td>\n",
       "      <td>metavision</td>\n",
       "      <td>Scores - APACHE II</td>\n",
       "      <td>Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14519</th>\n",
       "      <td>226758</td>\n",
       "      <td>GCSVerbalApacheIIValue</td>\n",
       "      <td>metavision</td>\n",
       "      <td>Scores - APACHE II</td>\n",
       "      <td>Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14520</th>\n",
       "      <td>226759</td>\n",
       "      <td>HCO3ApacheIIValue</td>\n",
       "      <td>metavision</td>\n",
       "      <td>Scores - APACHE II</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14521</th>\n",
       "      <td>226760</td>\n",
       "      <td>HCO3Score</td>\n",
       "      <td>metavision</td>\n",
       "      <td>Scores - APACHE II</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14522</th>\n",
       "      <td>226761</td>\n",
       "      <td>HematocritApacheIIScore</td>\n",
       "      <td>metavision</td>\n",
       "      <td>Scores - APACHE II</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12487 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ITEMID                                        LABEL    DBSOURCE  \\\n",
       "ROW_ID                                                                    \n",
       "457        497  Patient controlled analgesia (PCA) [Inject]     carevue   \n",
       "458        498                            PCA Lockout (Min)     carevue   \n",
       "459        499                               PCA Medication     carevue   \n",
       "460        500                               PCA Total Dose     carevue   \n",
       "461        501                           PCV Exh Vt (Obser)     carevue   \n",
       "...        ...                                          ...         ...   \n",
       "14518   226757                        GCSMotorApacheIIValue  metavision   \n",
       "14519   226758                       GCSVerbalApacheIIValue  metavision   \n",
       "14520   226759                            HCO3ApacheIIValue  metavision   \n",
       "14521   226760                                    HCO3Score  metavision   \n",
       "14522   226761                      HematocritApacheIIScore  metavision   \n",
       "\n",
       "                  CATEGORY PARAM_TYPE  \n",
       "ROW_ID                                 \n",
       "457                    NaN        NaN  \n",
       "458                    NaN        NaN  \n",
       "459                    NaN        NaN  \n",
       "460                    NaN        NaN  \n",
       "461                    NaN        NaN  \n",
       "...                    ...        ...  \n",
       "14518   Scores - APACHE II       Text  \n",
       "14519   Scores - APACHE II       Text  \n",
       "14520   Scores - APACHE II    Numeric  \n",
       "14521   Scores - APACHE II    Numeric  \n",
       "14522   Scores - APACHE II    Numeric  \n",
       "\n",
       "[12487 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(data_path+'D_ITEMS.csv.gz', index_col=0,\n",
    "                  # dropped 'ABBREVIATION', 'LINKSTO', 'CONCEPTID', 'UNITNAME'\n",
    "                  usecols=['ROW_ID', 'ITEMID', 'LABEL', 'DBSOURCE', 'CATEGORY', 'PARAM_TYPE'],\n",
    "                  dtype={'ROW_ID': int, 'ITEMID': int, 'LABEL': str, 'DBSOURCE': 'category',\n",
    "                         'CATEGORY': 'category', 'PARAM_TYPE': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "stretch-polls",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as ds\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'A': ['1', '2', '3', np.nan], 'B': ['1', '2', '3', np.nan]}, dtype=str).to_csv('tmp.csv')\n",
    "\n",
    "for i, chunk in enumerate(pd.read_csv('tmp.csv', dtype={'A': str, 'B': str}, chunksize=1)):\n",
    "    # create a parquet table from your dataframe\n",
    "    table = pa.Table.from_pandas(chunk)\n",
    "    if i == 0:\n",
    "        schema = table.schema\n",
    "    # write direct to your parquet file\n",
    "    pq.write_to_dataset(table, root_path='./tmp.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "expired-tunisia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     A     B\n",
       "0         0.0     1     1\n",
       "1         1.0     2     2\n",
       "2         NaN     3     3\n",
       "3         NaN     1     1\n",
       "4         NaN     2     2\n",
       "5         NaN  None  None\n",
       "6         3.0  None  None\n",
       "7         2.0     3     3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset = ds.dataset('./tmp.parquet', schema=schema)\n",
    "dataset = ds.dataset('./tmp.parquet')\n",
    "dataset.to_table().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "automated-prophet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B\n",
       "0  1.0  1.0\n",
       "1  2.0  2.0\n",
       "2  3.0  3.0\n",
       "3  NaN  NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(dataset.schema.to_string())\n",
    "pd.read_csv('tmp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-revolution",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
