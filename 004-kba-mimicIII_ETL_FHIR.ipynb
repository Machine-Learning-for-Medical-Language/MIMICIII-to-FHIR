{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ideal-bathroom",
   "metadata": {},
   "source": [
    "# MIMIC-III tables to FHIR resource mapping in this notebook [NOT READY]\n",
    "\n",
    "||Original format | FHIR resource| Progress|Final Check|\n",
    "|------|:-----|:-----|:-----|---:---|\n",
    "|12|caregivers | practitioner| C,L,A|Done|\n",
    "|13|procedures_icd | procedure| C,L,A|Done|\n",
    "|14|procedureevents_mv | procedure| C,L,A|Done|\n",
    "|15|microbiology | specimen| C,L,A|Done|\n",
    "|16|outputevents | specimen| C,L,A|Done|\n",
    "|17|service | serviceRequest|C,L,A|Done|\n",
    "|18|callout | -|-|-|\n",
    "|19|transfers | -|-|-|\n",
    "|20|drgcodes | -|-|-|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "foreign-thesis",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rocky-content",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/mimic-iii-clinical-database-1.4/'\n",
    "output_path = './data/fhir_out/'\n",
    "file_ext = '.csv.gz'\n",
    "compression = 'gzip'\n",
    "\n",
    "data_files = os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-damages",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "reflected-efficiency",
   "metadata": {},
   "source": [
    "## fhir.practitioner table\n",
    "\n",
    "#### MAPPING:\n",
    "\n",
    "||Original format | FHIR resource format|\n",
    "|------|:-----|:-----|\n",
    "|1|mimic.caregivers.CGID|fhir.practitioner.identifier|\n",
    "|2|mimic.caregivers.LABEL|fhir.practitioner.qualification_category|\n",
    "|3|mimic.caregivers.DESCRIPTION|fhir.practitioner.qualification_label|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_caregivers(data_path, output_path):\n",
    "    caregivers = pd.read_csv(data_path+'CAREGIVERS'+file_ext, compression=compression)\n",
    "\n",
    "    caregivers.drop(['ROW_ID'], axis=1, inplace=True)\n",
    "\n",
    "    caregivers.rename(columns={'CGID':'identifier',\n",
    "                                 'LABEL':'qualification_label',\n",
    "                                 'DESCRIPTION':'qualification_category'}, inplace=True)\n",
    "\n",
    "    caregivers.to_csv(output_path+'practitioner.csv.gz', compression='gzip', index=False)\n",
    "    return caregivers\n",
    "\n",
    "practitioner = transform_caregivers(data_path, output_path)\n",
    "practitioner.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-influence",
   "metadata": {},
   "source": [
    "## fhir.procedure table\n",
    "\n",
    "#### PROCEDURES_ICD MAPPING:<br>\n",
    "||Original format | FHIR resource format|\n",
    "|------|:-----|:-----|\n",
    "|1|mimic.procedures_icd.ROW_ID | fhir.procedure.identifier|\n",
    "|2|mimic.procedures_icd.SUBJECT_ID | fhir.procedure.subject|\n",
    "|3|mimic.procedures_icd.HADM_ID | fhir.procedure.encounter|\n",
    "|4|mimic.procedures_icd.ICD9_CODE | fhir.procedure.code_icd9|\n",
    "\n",
    "#### PROCEDUREEVENTS_MV MAPPING:<br>\n",
    "||Original format | FHIR resource format|\n",
    "|------|:-----|:-----|\n",
    "|1|mimic.procedureevents_mv.ROW_ID | fhir.procedure.identifier|\n",
    "|2|mimic.procedureevents_mv.SUBJECT_ID | fhir.procedure.subject|\n",
    "|3|mimic.procedureevents_mv.HADM_ID | fhir.procedure.encounter|\n",
    "|4|mimic.procedureevents_mv.ICUSTAY_ID| fhir.procedure.partOf|\n",
    "|5|mimic.procedureevents_mv.STARTTIME| fhir.procedure.performedRange_start|\n",
    "|6|mimic.procedureevents_mv.ENDTIME| fhir.procedure.performedRange_end|\n",
    "|7|mimic.procedureevents_mv.ITEMID| fhir.procedure.code|\n",
    "|8|mimic.procedureevents_mv.VALUE| fhir.procedure.outcome_value|\n",
    "|9|mimic.procedureevents_mv.VALUEOM | fhir.procedure.outcome_unit|\n",
    "|10|mimic.procedureevents_mv.LOCATION| fhir.procedure.location_name|\n",
    "|11|mimic.procedureevents_mv.LOCATIONCATEGORY| fhir.procedure.location_category|\n",
    "|12|mimic.procedureevents_mv.CGID|fhir.procedure.performer|\n",
    "|13|mimic.procedureevents_mv.ORDERID| fhir.procedure.basedOn|\n",
    "|14|mimic.procedureevents_mv.LINKORDERID|fhir.procedure.basedOn_linked|\n",
    "|15|mimic.procedureevents_mv.ORDERCATEGORYNAME| fhir.procedure.category_order_name|\n",
    "|16|mimic.procedureevents_mv.SECONDARYORDERCATEGORYNAME|fhir.procedure.category_secOrder_name|\n",
    "|17|mimic.procedureevents_mv.ORDERCATEGORYDESCRIPTION|fhir.procedure.category_order_description|\n",
    "|18|mimic.procedureevents_mv.ISOPENBAG| fhir.procedure.usedReference_openBag|\n",
    "|19|mimic.procedureevents_mv.CONTINUEINEXTDEPT| fhir.procedure.report_contExtDep|\n",
    "|20|mimic.procedureevents_mv.CANCELREASON| fhir.procedure.report_cancelReason|\n",
    "|21|mimic.procedureevents_mv.STATUSDESCRIPTION| fhir.procedure.status|\n",
    "|22|mimic.procedureevents_mv.COMMENTS_EDITEDBY| fhir.procedure.report_editedBy|\n",
    "|23|mimic.procedureevents_mv.COMMENTS_CANCELEDBY| fhir.procedure.report_canceledBy|\n",
    "|24|mimic.procedureevents_mv.COMMENTS_DATE| fhir.procedure.report_canceledDate|\n",
    "|25|mimic.d_items.(LABEL+DBSOURCE+PARAM_TYPE)|mimic.procedure.note|\n",
    "|26|mimic.d_items.CATEGORY|mimic.procedure.category|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_procedures_icd(data_path, output_path):\n",
    "    procedures_icd = pd.read_csv(data_path+'PROCEDURES_ICD'+file_ext, compression=compression)\n",
    "    procedures_icd['followUp'] = procedures_icd.groupby('HADM_ID')['ROW_ID'].shift(-1)\n",
    "    procedures_icd.rename(columns={'ROW_ID':'identifier',\n",
    "                                   'SUBJECT_ID':'subject',\n",
    "                                   'HADM_ID':'encounter',\n",
    "                                   'ICD9_CODE':'code'}, inplace=True)\n",
    "\n",
    "    procedures_icd.to_csv(output_path+'procedure_icd9.csv.gz', compression='gzip', index=False)\n",
    "    return procedures_icd\n",
    "\n",
    "procedure_icd9 = transform_procedures_icd(data_path, output_path)\n",
    "procedure_icd9.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-discussion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_procedurevents_mv(data_path, output_path):\n",
    "    procedurevents_mv = pd.read_csv(data_path+'PROCEDUREEVENTS_MV'+file_ext, compression=compression)\n",
    "    d_items = pd.read_csv(data_path+'D_ITEMS'+file_ext, compression=compression, index_col=0)\n",
    "    \n",
    "    procedurevents_mv = pd.merge(procedurevents_mv, d_items, on='ITEMID')\n",
    "    \n",
    "    procedurevents_mv.STARTTIME = pd.to_datetime(procedurevents_mv.STARTTIME, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
    "    procedurevents_mv.ENDTIME = pd.to_datetime(procedurevents_mv.ENDTIME, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
    "    procedurevents_mv.COMMENTS_DATE = pd.to_datetime(procedurevents_mv.COMMENTS_DATE, format = '%Y-%m-%d', errors = 'coerce')\n",
    "    \n",
    "    procedurevents_mv['note'] = procedurevents_mv['LABEL'] + ' ' + procedurevents_mv['DBSOURCE'] + ' ' + procedurevents_mv['PARAM_TYPE']\n",
    "    \n",
    "    procedurevents_mv.drop(['LABEL', 'PARAM_TYPE', 'STORETIME', 'ABBREVIATION', 'DBSOURCE', 'LINKSTO', 'CONCEPTID', 'UNITNAME'], axis=1, inplace=True)\n",
    "\n",
    "    procedurevents_mv.rename(columns={'ROW_ID':'identifier',\n",
    "                                      'SUBJECT_ID':'subject',\n",
    "                                      'HADM_ID':'encounter',\n",
    "                                      'ICUSTAY_ID':'partOf',\n",
    "                                      'STARTTIME':'performedRange_start',\n",
    "                                      'ENDTIME':'performedRange_end',\n",
    "                                      'ITEMID':'code',\n",
    "                                      'VALUE':'outcome_value',\n",
    "                                      'VALUEUOM':'outcome_unit',\n",
    "                                      'LOCATION':'location_name',\n",
    "                                      'LOCATIONCATEGORY':'location_category',\n",
    "                                      'CGID':'performer',\n",
    "                                      'ORDERID':'basedOn',\n",
    "                                      'LINKORDERID':'basedOn_linked',\n",
    "                                      'ORDERCATEGORYNAME':'category_order_name',\n",
    "                                      'SECONDARYORDERCATEGORYNAME':'category_secOrder_name',\n",
    "                                      'ORDERCATEGORYDESCRIPTION':'category_order_description',\n",
    "                                      'ISOPENBAG':'usedReference_openBag',\n",
    "                                      'CONTINUEINNEXTDEPT':'report_contNextDep',\n",
    "                                      'CANCELREASON':'report_cancelReason',\n",
    "                                      'STATUSDESCRIPTION':'status',\n",
    "                                      'COMMENTS_EDITEDBY':'report_editedBy',\n",
    "                                      'COMMENTS_CANCELEDBY':'report_canceledBy',\n",
    "                                      'COMMENTS_DATE':'report_canceledDate',\n",
    "                                      'CATEGORY':'category'\n",
    "                                     }, inplace=True)\n",
    "\n",
    "    procedurevents_mv.to_csv(output_path+'procedure_mv.csv.gz', compression='gzip', index=False)\n",
    "    return procedurevents_mv\n",
    "\n",
    "procedure_mv = transform_procedurevents_mv(data_path, output_path)\n",
    "procedure_mv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-milan",
   "metadata": {},
   "source": [
    "## fhir.specimen table\n",
    "\n",
    "#### OUTPUTEVENTS MAPPING:<br>\n",
    "\n",
    "||Original format | FHIR resource format|\n",
    "|------|:-----|:-----|\n",
    "|1|mimic.outputevents:ROW_ID | fhir.specimen.identifier|\n",
    "|2|mimic.outputevents.SUBJECT_ID | fhir.specimen.subject|\n",
    "|3|mimic.outputevents.HADM_ID | fhir.specimen.request_encounter_admission|\n",
    "|4|mimic.outputevents.ICUSTAY_ID | fhir.specimen.request_encounter_icustay|\n",
    "|5|mimic.outputevents.ITEMID | fhir.specimen.type_code|\n",
    "|6|mimic.d_items.CATEGORY | fhir.specimen.type_category|\n",
    "|7|mimic.outputevents.CGID | fhir.specimen.collection_collector|\n",
    "|8|mimic.outputevents.CHARTTIME | fhir.specimen.collection_dateTime|\n",
    "|9|mimic.outputevents.VALUE | fhir.specimen.collection_quantity|\n",
    "|10|mimic.outputevents.VALUEUOM | fhir.specimen.collection_unit|\n",
    "|11|mimic.outputevents.NEWBOTTLE | fhir.specimen.collection_newBottle|\n",
    "|12|mimic.outputevents.(STOPPED+ISERROR) | fhir.specimen.status|\n",
    "|13|mimic.d_items.(LABEL+DBSOURCE+PARAM_TYPE) | fhir.specimen.note|\n",
    "\n",
    "#### MICROBIOLOGYEVENTS MAPPING:<br>\n",
    "\n",
    "||Original format | FHIR resource format|\n",
    "|------|:-----|:-----|\n",
    "|1|mimic.microbiologyevents.ROW_ID| fhir.specimen.identifier|\n",
    "|2|mimic.microbiologyevents.SUBJECT_ID | fhir.specimen.subject|\n",
    "|3|mimic.microbiologyevents.HADM_ID | fhir.specimen.request_encounter_admission|\n",
    "|4|mimic.microbiologyevents.CHARTTIME | fhir.specimen.collection_dateTime|\n",
    "|5|mimic.microbiologyevents.SPEC_ITEMID | fhir.specimen.type_code|\n",
    "|6|mimic.microbiologyevents.SPEC_TYPE_DESC | fhir.specimen.type_name|\n",
    "|7|mimic.d_items(on SPEC).CATEGORY | fhir.specimen.type_category|\n",
    "|8|mimic.microbiologyevents.ORG_ITEMID | fhir.specimen.method_bact_code|\n",
    "|9|mimic.microbiologyevents.ORG_NAME | fhir.specimen.method_bact_name|\n",
    "|10|mimic.microbiologyevents.ISOLATE_NUM | fhir.specimen.method_colNum|\n",
    "|11|mimic.microbiologyevents.AB_ITEMID | fhir.specimen.method_antibiotic_code|\n",
    "|12|mimic.microbiologyevents.AB_NAME | fhir.specimen.method_antibiotic_name|\n",
    "|13|mimic.microbiologyevents.DILUTION_TEXT | fhir.specimen.method_dilution_description|\n",
    "|14|mimic.microbiologyevents.DILUTION_COMPARISON | fhir.specimen.method_dilution_comp|\n",
    "|15|mimic.microbiologyevents.DILUTION_VALUE | fhir.specimen.method_dilution_value|\n",
    "|16|mimic.microbiologyevents.INTERPRETATION | fhir.specimen.note_interpretation|\n",
    "|17|mimic.d_items_(SPEC/ORG/AB).(LABEL+PARAM_TYPE+DBSOURCE) | fhir.specimen.note|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-smart",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_outputevents(data_path, output_path):\n",
    "    outputevents = pd.read_csv(data_path+'OUTPUTEVENTS'+file_ext, compression=compression)\n",
    "    d_items = pd.read_csv(data_path+'D_ITEMS'+file_ext, compression=compression, index_col=0)\n",
    "    \n",
    "    specimen_oe = pd.merge(outputevents, d_items, on='ITEMID')\n",
    "    specimen_oe.CHARTTIME = pd.to_datetime(specimen_oe.CHARTTIME, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
    "\n",
    "    # Replace NaN in columns with empty strings so that concatenation in notes works\n",
    "    specimen_oe['PARAM_TYPE'].replace(np.NaN, '', regex=True, inplace=True)\n",
    "    specimen_oe['note'] = specimen_oe['LABEL'] + ' ' + specimen_oe['DBSOURCE'] + ' ' + specimen_oe['PARAM_TYPE']\n",
    "\n",
    "    # Combine STOPPED and ISERROR column, Errorneous notes entries will be eliminated later on\n",
    "    specimen_oe.loc[specimen_oe.ISERROR==1,'STOPPED'] = 'Error'\n",
    "\n",
    "    # Drop Columns not needed anymore\n",
    "    specimen_oe.drop(['LABEL', 'PARAM_TYPE', 'STORETIME', 'ISERROR', 'ABBREVIATION', 'DBSOURCE', 'LINKSTO', 'CONCEPTID', 'UNITNAME'], axis=1, inplace=True)\n",
    "\n",
    "    specimen_oe.rename(columns={'ROW_ID':'identifier',\n",
    "                                'SUBJECT_ID':'subject',\n",
    "                                'HADM_ID':'request_encounter_admission',\n",
    "                                'ICUSTAY_ID':'request_encounter_icustay',\n",
    "                                'ITEMID':'type_code',\n",
    "                                'CATEGORY':'type_category',\n",
    "                                'CGID':'collector',\n",
    "                                'CHARTTIME':'collected_dateTime',\n",
    "                                'VALUE':'collection_quantity',\n",
    "                                'VALUEUOM':'collection_unit',\n",
    "                                'NEWBOTTLE':'collection_newBottle',\n",
    "                                'STOPPED':'status'}, inplace=True)\n",
    "    \n",
    "    specimen_oe = specimen_oe.reindex(columns=['identifier',\n",
    "                                                'subject',\n",
    "                                                'request_encounter_admission',\n",
    "                                                'request_encounter_icustay',\n",
    "                                                'type_code',\n",
    "                                                'type_category',\n",
    "                                                'collection_collector',\n",
    "                                                'collection_dateTime',\n",
    "                                                'collection_quantity',\n",
    "                                                'collection_unit',\n",
    "                                                'collection_newBottle',\n",
    "                                                'status',\n",
    "                                                'note'], copy=False)\n",
    "\n",
    "    specimen_oe.to_csv(output_path+'specimen_oe.csv.gz', compression='gzip', index=False)\n",
    "    return specimen_oe\n",
    "\n",
    "specimen_oe = transform_outputevents(data_path, output_path)\n",
    "specimen_oe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-classics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_microbiologyevents(data_path, output_path):\n",
    "    microbiologyevents = pd.read_csv(data_path+'MICROBIOLOGYEVENTS'+file_ext, compression=compression)\n",
    "    d_items = pd.read_csv(data_path+'D_ITEMS'+file_ext, compression=compression, index_col=0)\n",
    "    \n",
    "    specimen_mbe = pd.merge(microbiologyevents, d_items[['ITEMID','LABEL','DBSOURCE','PARAM_TYPE','CATEGORY']], left_on='SPEC_ITEMID', right_on='ITEMID')\n",
    "    specimen_mbe = pd.merge(specimen_mbe, d_items[['ITEMID','LABEL','DBSOURCE','PARAM_TYPE']], left_on='ORG_ITEMID', right_on='ITEMID', suffixes=('','_org'))\n",
    "    specimen_mbe = pd.merge(specimen_mbe, d_items[['ITEMID','LABEL','DBSOURCE','PARAM_TYPE']], left_on='AB_ITEMID', right_on='ITEMID', suffixes=('','_ab'))\n",
    "\n",
    "    specimen_mbe.CHARTTIME = pd.to_datetime(specimen_mbe.CHARTTIME, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
    "\n",
    "    # Replace NaN in columns with empty strings so that concatenation in notes works\n",
    "    specimen_mbe['PARAM_TYPE'].replace(np.NaN, '', regex=True, inplace=True)\n",
    "    specimen_mbe['PARAM_TYPE_org'].replace(np.NaN, '', regex=True, inplace=True)\n",
    "    specimen_mbe['PARAM_TYPE_ab'].replace(np.NaN, '', regex=True, inplace=True)\n",
    "\n",
    "    specimen_mbe['note'] = specimen_mbe['LABEL'] + ' ' + specimen_mbe['DBSOURCE'] + ' ' + specimen_mbe['PARAM_TYPE']  + ' ' + specimen_mbe['LABEL_org'] + ' ' + specimen_mbe['DBSOURCE_org'] + ' ' + specimen_mbe['PARAM_TYPE_org']  + ' ' + specimen_mbe['LABEL_ab'] + ' ' + specimen_mbe['DBSOURCE_ab'] + ' ' + specimen_mbe['PARAM_TYPE_ab']\n",
    "\n",
    "    # Drop columns combined to note field\n",
    "    specimen_mbe.drop(['CHARTDATE'], axis=1, inplace=True)\n",
    "    specimen_mbe.drop(['ITEMID', 'LABEL', 'PARAM_TYPE','DBSOURCE'], axis=1, inplace=True)\n",
    "    specimen_mbe.drop(['ITEMID_org', 'LABEL_org', 'PARAM_TYPE_org','DBSOURCE_org'], axis=1, inplace=True)\n",
    "    specimen_mbe.drop(['ITEMID_ab', 'LABEL_ab', 'PARAM_TYPE_ab','DBSOURCE_ab'], axis=1, inplace=True)\n",
    "\n",
    "    specimen_mbe.rename(columns={'ROW_ID':'identifier',\n",
    "                                 'SUBJECT_ID':'subject',\n",
    "                                 'HADM_ID':'request_encounter_admission',\n",
    "                                 'CHARTTIME':'collection_dateTime',\n",
    "                                 'SPEC_ITEMID':'type_code',\n",
    "                                 'SPEC_TYPE_DESC':'type_name',\n",
    "                                 'CATEGORY':'type_category',\n",
    "                                 'ORG_ITEMID':'method_bact_code',\n",
    "                                 'ORG_NAME':'method_bact_name',\n",
    "                                 'ISOLATE_NUM':'method_colNum',\n",
    "                                 'AB_ITEMID':'method_antibiotic_code',\n",
    "                                 'AB_NAME':'method_antibiotic_name',\n",
    "                                 'DILUTION_TEXT':'method_dilution_description',\n",
    "                                 'DILUTION_COMPARISON':'method_dilution_comp',\n",
    "                                 'DILUTION_VALUE':'method_dilution_value',\n",
    "                                 'INTERPRETATION':'note_interpretation'}, inplace=True)\n",
    "\n",
    "    specimen_mbe.to_csv(output_path+'specimen_mbe.csv.gz', compression='gzip', index=False)\n",
    "    return specimen_mbe\n",
    "\n",
    "specimen_mbe = transform_microbiologyevents(data_path, output_path)\n",
    "specimen_mbe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-picnic",
   "metadata": {},
   "source": [
    "## fhir.serviceRequest table\n",
    "\n",
    "#### MAPPING:<br>\n",
    "\n",
    "||Original format | FHIR resource format|\n",
    "|------|:-----|:-----|\n",
    "|1|mimic.services.ROW_ID | fhir.serviceRequest.identifier|\n",
    "|2|mimic.services.SUBJECT_ID | fhir.serviceRequest.subject|\n",
    "|3|mimic.services.HADM_ID | fhir.serviceRequest.encounter|\n",
    "|4|mimic.services.TRANSFERTIME | fhir.serviceRequest.occuranceDateTime|\n",
    "|5|mimic.services.PREV_SERVICE | fhir.serviceRequest.replaces|\n",
    "|6|mimic.services.CURR_SERVICE | fhir.serviceRequest.code_name|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-quebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_services(data_path, output_path):\n",
    "    services = pd.read_csv(data_path+'SERVICES'+file_ext, compression=compression)\n",
    "    \n",
    "    services.TRANSFERTIME = pd.to_datetime(services.TRANSFERTIME, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
    "\n",
    "    services.rename(columns={'ROW_ID':'identifier',\n",
    "                             'SUBJECT_ID':'subject',\n",
    "                             'HADM_ID':'encounter',\n",
    "                             'TRANSFERTIME':'occuranceDateTime',\n",
    "                             'PREV_SERVICE':'replaces',\n",
    "                             'CURR_SERVICE':'code_name'}, inplace=True)\n",
    "    \n",
    "    services.to_csv(output_path+'services.csv.gz', compression='gzip', index=False)\n",
    "    return services\n",
    "\n",
    "serviceRequest = transform_services(data_path, output_path)\n",
    "serviceRequest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-garlic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
